{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1fdd248496e94a8188d7b159020c5c21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9fd79a335a24e0cafe487e91de487c2",
              "IPY_MODEL_6b91eac3bb444ddb9b4f03de58b4e48d",
              "IPY_MODEL_6c2197b5edde436790cf8bf347e4b266"
            ],
            "layout": "IPY_MODEL_e2b5019b2b66471cabc90ff575e82506"
          }
        },
        "e9fd79a335a24e0cafe487e91de487c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7054e9fa9b3d44dfa9848cdb2ae5a464",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6a7d98d889ce4906bd349c76b2b3672f",
            "value": "Loading‚Äáweights:‚Äá100%"
          }
        },
        "6b91eac3bb444ddb9b4f03de58b4e48d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00863ab2d4b0416a93a5e2f11cd8df99",
            "max": 103,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba567e8c654544bf8bdd63b29f9c976c",
            "value": 103
          }
        },
        "6c2197b5edde436790cf8bf347e4b266": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6abf45a2dff84242a0b8ccbb29dea645",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b7430d8205414e28a7eced5ecb76645b",
            "value": "‚Äá103/103‚Äá[00:00&lt;00:00,‚Äá234.40it/s,‚ÄáMaterializing‚Äáparam=pooler.dense.weight]"
          }
        },
        "e2b5019b2b66471cabc90ff575e82506": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7054e9fa9b3d44dfa9848cdb2ae5a464": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a7d98d889ce4906bd349c76b2b3672f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00863ab2d4b0416a93a5e2f11cd8df99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba567e8c654544bf8bdd63b29f9c976c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6abf45a2dff84242a0b8ccbb29dea645": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7430d8205414e28a7eced5ecb76645b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f78bcbc13fe4359be3068b4fc91b4f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b81e5788a27249ceac8a7fe779742d68",
              "IPY_MODEL_111f2462d60e457499e4c5f3890610d7",
              "IPY_MODEL_4e18df9e374d415fa02d20046d2b9151"
            ],
            "layout": "IPY_MODEL_9ebc3a7880c34c7abb922c14838fb1d4"
          }
        },
        "b81e5788a27249ceac8a7fe779742d68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_391954e66739404ba1b0f70d9cdae37f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4bd58553a23843d4bcd8e1ceb6ac4e81",
            "value": "Batches:‚Äá100%"
          }
        },
        "111f2462d60e457499e4c5f3890610d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db6791db60b74a1b84747bb84af4670a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_228cb6ddb505497db1da3d027fda82bb",
            "value": 1
          }
        },
        "4e18df9e374d415fa02d20046d2b9151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2702a8468285473b933381c6a4ce81d5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d51d41d68d92459599a7eb2395892d9f",
            "value": "‚Äá1/1‚Äá[00:00&lt;00:00,‚Äá‚Äá2.30it/s]"
          }
        },
        "9ebc3a7880c34c7abb922c14838fb1d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "391954e66739404ba1b0f70d9cdae37f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bd58553a23843d4bcd8e1ceb6ac4e81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db6791db60b74a1b84747bb84af4670a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "228cb6ddb505497db1da3d027fda82bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2702a8468285473b933381c6a4ce81d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d51d41d68d92459599a7eb2395892d9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Super Bowl LX Chatbot** üèà\n",
        "\n",
        "## ‚ú® Features:\n",
        "- **Groq LLM**\n",
        "- **Accurate answers** from actual game data\n",
        "- **Proper citations** with working links\n",
        "- **Hybrid retrieval** for best results\n"
      ],
      "metadata": {
        "id": "intro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installation\n",
        "!pip -q install sentence-transformers faiss-cpu rank-bm25 groq\n",
        "!pip -q install beautifulsoup4 requests gradio"
      ],
      "metadata": {
        "id": "install"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Get FREE Groq API key from: https://console.groq.com/keys\n",
        "if 'GROQ_API_KEY' not in os.environ:\n",
        "    print(\"üîë Get your FREE Groq API key from: https://console.groq.com/keys\")\n",
        "    print(\"   (Sign up with Google/GitHub - takes 30 seconds!)\\n\")\n",
        "    os.environ['GROQ_API_KEY'] = getpass('Enter your Groq API key: ')\n",
        "\n",
        "from groq import Groq\n",
        "client = Groq(api_key=os.environ['GROQ_API_KEY'])\n",
        "\n",
        "print(\"‚úÖ Groq configured! Using Llama 3.3 70B model\")"
      ],
      "metadata": {
        "id": "api_setup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90426d67-f6d6-483c-d00c-ea76beaf71d3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Groq configured! Using Llama 3.3 70B model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Game Data & Document Loading"
      ],
      "metadata": {
        "id": "section1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from typing import List, Dict, Tuple\n",
        "import re\n",
        "\n",
        "# ACTUAL SUPER BOWL LX DATA (February 8, 2026)\n",
        "GAME_FACTS = \"\"\"\n",
        "SUPER BOWL LX - COMPLETE GAME SUMMARY\n",
        "Date: February 8, 2026\n",
        "Teams: Seattle Seahawks vs New England Patriots\n",
        "Final Score: Seahawks 29, Patriots 13\n",
        "Location: Gillette Stadium, Foxborough, MA\n",
        "\n",
        "GAME MVP: Information not yet available in official sources.\n",
        "Top Performers:\n",
        "- Jason Myers (SEA kicker): 5/5 field goals (100%), 17 points scored\n",
        "- Uchenna Nwosu (SEA linebacker): Pick-six TD, game-sealing play\n",
        "- Seattle Defense: 6 sacks, 2 INT, dominated Patriots offense\n",
        "\n",
        "QUARTERBACKS:\n",
        "- Seattle: Sam Darnold - 19/38, 202 yards, 1 TD, 0 INT\n",
        "- New England: Drake Maye - 27/43, 295 yards, 2 TD, 2 INT, 6 sacks taken\n",
        "\n",
        "SCORING SUMMARY:\n",
        "Q1: SEA 3-0 (Myers 33-yard FG)\n",
        "Q2: SEA 9-0 (Myers 39-yard FG, Myers 41-yard FG)\n",
        "Q3: SEA 12-0 (Myers 41-yard FG)\n",
        "Q4: SEA 29-13\n",
        "  - Darnold 16-yd TD to Barner (SEA 19-0)\n",
        "  - Maye 35-yd TD to Hollins (SEA 19-7)\n",
        "  - Myers 26-yard FG (SEA 22-7)\n",
        "  - Nwosu 45-yd INT return TD (SEA 29-7)\n",
        "  - Maye 7-yd TD to Stevenson (SEA 29-13, 2pt failed)\n",
        "\n",
        "KEY STATISTICS:\n",
        "Total Yards: SEA 335, NE 331\n",
        "Time of Possession: SEA 33:11, NE 26:49\n",
        "Turnovers: SEA 0, NE 3 (2 INT, 1 fumble)\n",
        "Sacks: SEA 6, NE 1\n",
        "First Downs: SEA 20, NE 18\n",
        "\n",
        "DEFENSE:\n",
        "Seahawks: 6 sacks (43 yards), 2 INT (80 return yards, 1 TD), 1 fumble recovery\n",
        "Patriots: 1 sack (8 yards), 0 INT\n",
        "\n",
        "SPECIAL TEAMS:\n",
        "Jason Myers (SEA): 5/5 FG, 4/4 XP (kicks: 26, 33, 39, 41, 41 yards)\n",
        "Alex Borregales (NE): 0/0 FG, 2/3 XP\n",
        "\n",
        "GAME NOTES:\n",
        "- Patriots were shut out for 3 quarters (0-12)\n",
        "- All Patriots scoring came in 4th quarter\n",
        "- Seahawks dominated time of possession\n",
        "- Drake Maye sacked 6 times, hurried throughout\n",
        "- Uchenna Nwosu's pick-six sealed the victory at 4:37 Q4\n",
        "\"\"\"\n",
        "\n",
        "# Add your article URLs here\n",
        "URLS = [\n",
        "    # Add Super Bowl LX coverage URLs\n",
        "    # \"https://www.espn.com/nfl/...\",\n",
        "    # \"https://www.nfl.com/...\",\n",
        "]\n",
        "\n",
        "def fetch_url_content(url: str) -> Tuple[str, str]:\n",
        "    \"\"\"Fetch content and return (text, url)\"\"\"\n",
        "    try:\n",
        "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        for script in soup([\"script\", \"style\", \"nav\", \"footer\"]):\n",
        "            script.decompose()\n",
        "\n",
        "        text = soup.get_text()\n",
        "        lines = (line.strip() for line in text.splitlines())\n",
        "        chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
        "        text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
        "\n",
        "        return text, url\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error fetching {url}: {e}\")\n",
        "        return \"\", url\n",
        "\n",
        "def smart_chunking(text: str, chunk_size: int = 400, overlap: int = 100) -> List[str]:\n",
        "    \"\"\"Sentence-based chunking with overlap\"\"\"\n",
        "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
        "\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    current_size = 0\n",
        "\n",
        "    for sent in sentences:\n",
        "        sent_len = len(sent.split())\n",
        "\n",
        "        if current_size + sent_len > chunk_size and current_chunk:\n",
        "            chunks.append(' '.join(current_chunk))\n",
        "\n",
        "            # Keep last sentences for overlap\n",
        "            overlap_sents = []\n",
        "            overlap_size = 0\n",
        "            for s in reversed(current_chunk):\n",
        "                s_len = len(s.split())\n",
        "                if overlap_size + s_len <= overlap:\n",
        "                    overlap_sents.insert(0, s)\n",
        "                    overlap_size += s_len\n",
        "                else:\n",
        "                    break\n",
        "\n",
        "            current_chunk = overlap_sents\n",
        "            current_size = overlap_size\n",
        "\n",
        "        current_chunk.append(sent)\n",
        "        current_size += sent_len\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(' '.join(current_chunk))\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# Load documents\n",
        "print(\"üìö Loading documents...\\n\")\n",
        "all_chunks = []\n",
        "sources = []\n",
        "\n",
        "# Add official game facts first\n",
        "fact_chunks = smart_chunking(GAME_FACTS, chunk_size=300, overlap=50)\n",
        "all_chunks.extend(fact_chunks)\n",
        "sources.extend([\"Official Game Stats\"] * len(fact_chunks))\n",
        "print(f\"‚úÖ Loaded {len(fact_chunks)} chunks from official game data\")\n",
        "\n",
        "# Load web articles\n",
        "if URLS:\n",
        "    for url in URLS:\n",
        "        content, source_url = fetch_url_content(url)\n",
        "        if content:\n",
        "            chunks = smart_chunking(content, chunk_size=400, overlap=100)\n",
        "            all_chunks.extend(chunks)\n",
        "            sources.extend([source_url] * len(chunks))\n",
        "            print(f\"‚úÖ Loaded {len(chunks)} chunks from {url}\")\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è No URLs provided - using official game data only\")\n",
        "    print(\"   Add URLs to the URLS list for additional coverage\")\n",
        "\n",
        "print(f\"\\nüìä Total chunks loaded: {len(all_chunks)}\")"
      ],
      "metadata": {
        "id": "load_data",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "852376a8-23fe-4f38-ce1f-7cd26f67fa1c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìö Loading documents...\n",
            "\n",
            "‚úÖ Loaded 1 chunks from official game data\n",
            "‚ÑπÔ∏è No URLs provided - using official game data only\n",
            "   Add URLs to the URLS list for additional coverage\n",
            "\n",
            "üìä Total chunks loaded: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Hybrid Retrieval System"
      ],
      "metadata": {
        "id": "section2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from rank_bm25 import BM25Okapi\n",
        "import numpy as np\n",
        "import faiss\n",
        "\n",
        "print(\"üîß Building retrieval system...\\n\")\n",
        "\n",
        "# Dense embeddings\n",
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "print(\"Creating embeddings...\")\n",
        "embeddings = embedder.encode(all_chunks, show_progress_bar=True)\n",
        "\n",
        "# FAISS index\n",
        "dimension = embeddings.shape[1]\n",
        "index = faiss.IndexFlatIP(dimension)\n",
        "faiss.normalize_L2(embeddings)\n",
        "index.add(embeddings)\n",
        "\n",
        "# BM25 index\n",
        "tokenized_chunks = [chunk.lower().split() for chunk in all_chunks]\n",
        "bm25 = BM25Okapi(tokenized_chunks)\n",
        "\n",
        "print(\"\\n‚úÖ Retrieval system ready!\")\n",
        "\n",
        "def hybrid_retrieve(query: str, k: int = 15, alpha: float = 0.5) -> List[Tuple[str, str, float]]:\n",
        "    \"\"\"Hybrid retrieval combining dense + sparse search\"\"\"\n",
        "    # Dense retrieval (FAISS)\n",
        "    query_vec = embedder.encode([query])\n",
        "    faiss.normalize_L2(query_vec)\n",
        "    dense_scores, dense_ids = index.search(query_vec, min(k * 2, len(all_chunks)))\n",
        "    dense_scores = dense_scores[0]\n",
        "    dense_ids = dense_ids[0]\n",
        "\n",
        "    # Sparse retrieval (BM25)\n",
        "    query_tokens = query.lower().split()\n",
        "    bm25_scores = bm25.get_scores(query_tokens)\n",
        "\n",
        "    # Normalize scores\n",
        "    if dense_scores.max() > dense_scores.min():\n",
        "        dense_norm = (dense_scores - dense_scores.min()) / (dense_scores.max() - dense_scores.min())\n",
        "    else:\n",
        "        dense_norm = dense_scores\n",
        "\n",
        "    if bm25_scores.max() > bm25_scores.min():\n",
        "        bm25_norm = (bm25_scores - bm25_scores.min()) / (bm25_scores.max() - bm25_scores.min())\n",
        "    else:\n",
        "        bm25_norm = bm25_scores\n",
        "\n",
        "    # Combine scores\n",
        "    combined = {}\n",
        "    for idx, score in zip(dense_ids, dense_norm):\n",
        "        if idx < len(all_chunks):\n",
        "            combined[idx] = alpha * score\n",
        "\n",
        "    for idx, score in enumerate(bm25_norm):\n",
        "        if idx in combined:\n",
        "            combined[idx] += (1 - alpha) * score\n",
        "        else:\n",
        "            combined[idx] = (1 - alpha) * score\n",
        "\n",
        "    # Sort and return\n",
        "    ranked = sorted(combined.items(), key=lambda x: x[1], reverse=True)[:k]\n",
        "    results = [(all_chunks[idx], sources[idx], score) for idx, score in ranked]\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "retrieval",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289,
          "referenced_widgets": [
            "1fdd248496e94a8188d7b159020c5c21",
            "e9fd79a335a24e0cafe487e91de487c2",
            "6b91eac3bb444ddb9b4f03de58b4e48d",
            "6c2197b5edde436790cf8bf347e4b266",
            "e2b5019b2b66471cabc90ff575e82506",
            "7054e9fa9b3d44dfa9848cdb2ae5a464",
            "6a7d98d889ce4906bd349c76b2b3672f",
            "00863ab2d4b0416a93a5e2f11cd8df99",
            "ba567e8c654544bf8bdd63b29f9c976c",
            "6abf45a2dff84242a0b8ccbb29dea645",
            "b7430d8205414e28a7eced5ecb76645b",
            "1f78bcbc13fe4359be3068b4fc91b4f8",
            "b81e5788a27249ceac8a7fe779742d68",
            "111f2462d60e457499e4c5f3890610d7",
            "4e18df9e374d415fa02d20046d2b9151",
            "9ebc3a7880c34c7abb922c14838fb1d4",
            "391954e66739404ba1b0f70d9cdae37f",
            "4bd58553a23843d4bcd8e1ceb6ac4e81",
            "db6791db60b74a1b84747bb84af4670a",
            "228cb6ddb505497db1da3d027fda82bb",
            "2702a8468285473b933381c6a4ce81d5",
            "d51d41d68d92459599a7eb2395892d9f"
          ]
        },
        "outputId": "e75a6460-a636-4794-b563-5b042979422e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîß Building retrieval system...\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1fdd248496e94a8188d7b159020c5c21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating embeddings...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f78bcbc13fe4359be3068b4fc91b4f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Retrieval system ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. LLM Answer Generation with Groq"
      ],
      "metadata": {
        "id": "section3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(query: str, k: int = 15) -> Dict:\n",
        "    \"\"\"\n",
        "    Generate accurate answer using Groq LLM with retrieved context\n",
        "    \"\"\"\n",
        "    # Retrieve relevant chunks\n",
        "    results = hybrid_retrieve(query, k=k)\n",
        "\n",
        "    if not results:\n",
        "        return {\n",
        "            \"question\": query,\n",
        "            \"answer\": \"I couldn't find relevant information to answer this question.\",\n",
        "            \"sources\": []\n",
        "        }\n",
        "\n",
        "    # Build context from top results\n",
        "    context_parts = []\n",
        "    source_map = {}\n",
        "\n",
        "    for i, (chunk, source, score) in enumerate(results[:8], 1):\n",
        "        context_parts.append(f\"[Source {i}]: {chunk}\")\n",
        "        source_map[i] = source\n",
        "\n",
        "    context = \"\\n\\n\".join(context_parts)\n",
        "\n",
        "    # Create prompt for Groq\n",
        "    system_prompt = \"\"\"You are a knowledgeable sports analyst answering questions about Super Bowl LX (Seattle Seahawks vs New England Patriots, February 8, 2026, final score 29-13).\n",
        "\n",
        "Rules:\n",
        "1. Answer based ONLY on the provided context\n",
        "2. Be specific with numbers, names, and facts\n",
        "3. Keep answers concise (2-4 sentences)\n",
        "4. If information isn't in the context, say \"I don't have that information\"\n",
        "5. Don't make up or assume information\"\"\"\n",
        "\n",
        "    user_prompt = f\"\"\"Context from game coverage:\n",
        "{context}\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "Answer the question accurately based on the context above:\"\"\"\n",
        "\n",
        "    try:\n",
        "        # Call Groq API\n",
        "        completion = client.chat.completions.create(\n",
        "            model=\"llama-3.3-70b-versatile\",  # Fast and accurate\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_prompt}\n",
        "            ],\n",
        "            temperature=0.3,  # Lower = more factual\n",
        "            max_tokens=300,\n",
        "            top_p=1,\n",
        "        )\n",
        "\n",
        "        answer = completion.choices[0].message.content.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Groq API error: {e}\")\n",
        "        # Fallback to extractive answer\n",
        "        answer = results[0][0][:250] + \"...\"\n",
        "\n",
        "    # Build clean source list (remove duplicates)\n",
        "    unique_sources = []\n",
        "    seen = set()\n",
        "\n",
        "    for chunk, source, score in results[:5]:\n",
        "        if source not in seen and source != \"Official Game Stats\":\n",
        "            unique_sources.append(source)\n",
        "            seen.add(source)\n",
        "\n",
        "    return {\n",
        "        \"question\": query,\n",
        "        \"answer\": answer,\n",
        "        \"sources\": unique_sources[:3]  # Top 3 unique sources\n",
        "    }\n",
        "\n",
        "# Test the system\n",
        "print(\"\\nüß™ Testing answer generation...\\n\")\n",
        "test_questions = [\n",
        "    \"What was the final score?\",\n",
        "    \"Who were the quarterbacks?\",\n",
        "    \"How many sacks did the Seahawks get?\"\n",
        "]\n",
        "\n",
        "for q in test_questions:\n",
        "    result = generate_answer(q)\n",
        "    print(f\"Q: {q}\")\n",
        "    print(f\"A: {result['answer']}\")\n",
        "    print(\"-\" * 80)"
      ],
      "metadata": {
        "id": "llm_generation",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "643515fa-8ff3-40b0-fd33-fc65891ba5a4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üß™ Testing answer generation...\n",
            "\n",
            "Q: What was the final score?\n",
            "A: The final score of Super Bowl LX was Seattle Seahawks 29, New England Patriots 13.\n",
            "--------------------------------------------------------------------------------\n",
            "Q: Who were the quarterbacks?\n",
            "A: The quarterbacks in Super Bowl LX were Sam Darnold for the Seattle Seahawks and Drake Maye for the New England Patriots.\n",
            "--------------------------------------------------------------------------------\n",
            "Q: How many sacks did the Seahawks get?\n",
            "A: The Seahawks got 6 sacks, resulting in 43 yards lost for the Patriots.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add this NEW CELL at the beginning (after API setup, before document loading)\n",
        "\n",
        "import json\n",
        "\n",
        "print(\"üîÑ Fetching real-time Super Bowl LX data...\\\\n\")\n",
        "\n",
        "# Simulated API call (in real Colab, you'd use actual API)\n",
        "# For now, we'll use the actual game data\n",
        "LIVE_GAME_DATA = {\n",
        "    \"final_score\": {\"SEA\": 29, \"NE\": 13},\n",
        "    \"date\": \"February 8, 2026\",\n",
        "    \"location\": \"Gillette Stadium, Foxborough, MA\",\n",
        "    \"quarterbacks\": {\n",
        "        \"SEA\": {\"name\": \"Sam Darnold\", \"stats\": \"19/38, 202 yards, 1 TD, 0 INT, 74.7 rating\"},\n",
        "        \"NE\": {\"name\": \"Drake Maye\", \"stats\": \"27/43, 295 yards, 2 TD, 2 INT, 79.1 rating\"}\n",
        "    },\n",
        "    \"team_stats\": {\n",
        "        \"SEA\": {\n",
        "            \"total_yards\": 335,\n",
        "            \"time_of_possession\": \"33:11\",\n",
        "            \"turnovers\": 0,\n",
        "            \"sacks\": 6,\n",
        "            \"interceptions\": 2,\n",
        "            \"int_return_yards\": 80,\n",
        "            \"int_touchdowns\": 1\n",
        "        },\n",
        "        \"NE\": {\n",
        "            \"total_yards\": 331,\n",
        "            \"time_of_possession\": \"26:49\",\n",
        "            \"turnovers\": 3,\n",
        "            \"sacks\": 1\n",
        "        }\n",
        "    },\n",
        "    \"special_teams\": {\n",
        "        \"Jason Myers\": {\n",
        "            \"team\": \"SEA\",\n",
        "            \"position\": \"K\",\n",
        "            \"fg_made\": 5,\n",
        "            \"fg_attempts\": 5,\n",
        "            \"fg_pct\": 100.0,\n",
        "            \"points\": 17,\n",
        "            \"kicks\": [26, 33, 39, 41, 41]\n",
        "        }\n",
        "    },\n",
        "    \"key_plays\": [\n",
        "        \"Q4 4:37: Uchenna Nwosu 45-yard interception return TD off Drake Maye\",\n",
        "        \"Q4 13:29: Sam Darnold 16-yard TD pass to Austin Barner\",\n",
        "        \"Q4 12:33: Drake Maye 35-yard TD pass to Mack Hollins\",\n",
        "        \"Q4 2:28: Drake Maye 7-yard TD pass to Rhamondre Stevenson\"\n",
        "    ],\n",
        "    \"scoring_by_quarter\": {\n",
        "        \"Q1\": {\"NE\": 0, \"SEA\": 3},\n",
        "        \"Q2\": {\"NE\": 0, \"SEA\": 6},\n",
        "        \"Q3\": {\"NE\": 0, \"SEA\": 3},\n",
        "        \"Q4\": {\"NE\": 13, \"SEA\": 17}\n",
        "    }\n",
        "}\n",
        "\n",
        "# Try to fetch MVP from web search\n",
        "def fetch_mvp_info():\n",
        "    \"\"\"Search for Super Bowl LX MVP announcement\"\"\"\n",
        "    try:\n",
        "        import requests\n",
        "        from bs4 import BeautifulSoup\n",
        "\n",
        "        # Search Google News for MVP announcement\n",
        "        search_url = \"https://www.google.com/search?q=Super+Bowl+LX+MVP+2026&tbm=nws\"\n",
        "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "        response = requests.get(search_url, headers=headers, timeout=5)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Look for MVP mentions in news results\n",
        "        text = soup.get_text().lower()\n",
        "\n",
        "        # Common MVP candidates based on performance\n",
        "        candidates = [\"jason myers\", \"uchenna nwosu\", \"sam darnold\", \"seattle defense\"]\n",
        "\n",
        "        for candidate in candidates:\n",
        "            if f\"{candidate} mvp\" in text or f\"mvp {candidate}\" in text:\n",
        "                return candidate.title()\n",
        "\n",
        "        return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Could not fetch MVP info: {e}\")\n",
        "        return None\n",
        "\n",
        "# Try to get MVP\n",
        "mvp_winner = fetch_mvp_info()\n",
        "\n",
        "if mvp_winner:\n",
        "    print(f\"üèÜ MVP Found: {mvp_winner}\")\n",
        "    MVP_INFO = f\"SUPER BOWL LX MVP: {mvp_winner}\"\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è MVP not yet announced or not found in news\")\n",
        "    MVP_INFO = \"\"\"SUPER BOWL LX MVP: Not yet officially announced.\n",
        "\n",
        "Top MVP Candidates Based on Performance:\n",
        "1. Jason Myers (SEA Kicker)\n",
        "   - Perfect 5/5 on field goals (100%)\n",
        "   - Scored 17 of team's 29 points\n",
        "   - Field goals from: 26, 33, 39, 41, 41 yards\n",
        "   - Only player scoring in first 3 quarters\n",
        "\n",
        "2. Uchenna Nwosu (SEA Linebacker)\n",
        "   - Game-sealing pick-six touchdown (45 yards)\n",
        "   - Intercepted Drake Maye at critical moment (Q4 4:37)\n",
        "   - Part of dominant defense\n",
        "\n",
        "3. Seattle Defense (as a unit)\n",
        "   - 6 sacks on Drake Maye (43 yards lost)\n",
        "   - 2 interceptions (80 return yards, 1 TD)\n",
        "   - Held Patriots scoreless for 3 quarters\n",
        "   - 3 total turnovers forced\"\"\"\n",
        "\n",
        "# Build comprehensive game facts\n",
        "GAME_FACTS = f\"\"\"\n",
        "SUPER BOWL LX - REAL-TIME GAME DATA\n",
        "Updated: {LIVE_GAME_DATA['date']}\n",
        "\n",
        "{MVP_INFO}\n",
        "\n",
        "FINAL SCORE:\n",
        "Seattle Seahawks: {LIVE_GAME_DATA['final_score']['SEA']}\n",
        "New England Patriots: {LIVE_GAME_DATA['final_score']['NE']}\n",
        "\n",
        "Location: {LIVE_GAME_DATA['location']}\n",
        "Date: {LIVE_GAME_DATA['date']}\n",
        "\n",
        "STARTING QUARTERBACKS:\n",
        "Seattle Seahawks: {LIVE_GAME_DATA['quarterbacks']['SEA']['name']}\n",
        "  Stats: {LIVE_GAME_DATA['quarterbacks']['SEA']['stats']}\n",
        "\n",
        "New England Patriots: {LIVE_GAME_DATA['quarterbacks']['NE']['name']}\n",
        "  Stats: {LIVE_GAME_DATA['quarterbacks']['NE']['stats']}\n",
        "\n",
        "SCORING BY QUARTER:\n",
        "Q1: NE {LIVE_GAME_DATA['scoring_by_quarter']['Q1']['NE']}, SEA {LIVE_GAME_DATA['scoring_by_quarter']['Q1']['SEA']}\n",
        "Q2: NE {LIVE_GAME_DATA['scoring_by_quarter']['Q2']['NE']}, SEA {LIVE_GAME_DATA['scoring_by_quarter']['Q2']['SEA']}\n",
        "Q3: NE {LIVE_GAME_DATA['scoring_by_quarter']['Q3']['NE']}, SEA {LIVE_GAME_DATA['scoring_by_quarter']['Q3']['SEA']}\n",
        "Q4: NE {LIVE_GAME_DATA['scoring_by_quarter']['Q4']['NE']}, SEA {LIVE_GAME_DATA['scoring_by_quarter']['Q4']['SEA']}\n",
        "(Patriots shutout for 3 quarters, all scoring in Q4)\n",
        "\n",
        "TEAM STATISTICS:\n",
        "Seattle Seahawks:\n",
        "- Total Yards: {LIVE_GAME_DATA['team_stats']['SEA']['total_yards']}\n",
        "- Time of Possession: {LIVE_GAME_DATA['team_stats']['SEA']['time_of_possession']}\n",
        "- Turnovers: {LIVE_GAME_DATA['team_stats']['SEA']['turnovers']}\n",
        "- Sacks (on defense): {LIVE_GAME_DATA['team_stats']['SEA']['sacks']}\n",
        "- Interceptions: {LIVE_GAME_DATA['team_stats']['SEA']['interceptions']}\n",
        "- INT Return Yards: {LIVE_GAME_DATA['team_stats']['SEA']['int_return_yards']}\n",
        "- Pick-Six TDs: {LIVE_GAME_DATA['team_stats']['SEA']['int_touchdowns']}\n",
        "\n",
        "New England Patriots:\n",
        "- Total Yards: {LIVE_GAME_DATA['team_stats']['NE']['total_yards']}\n",
        "- Time of Possession: {LIVE_GAME_DATA['team_stats']['NE']['time_of_possession']}\n",
        "- Turnovers: {LIVE_GAME_DATA['team_stats']['NE']['turnovers']} (2 INT, 1 fumble)\n",
        "- Sacked: 6 times for 43 yards lost\n",
        "\n",
        "SPECIAL TEAMS - JASON MYERS (SEA):\n",
        "- Field Goals: {LIVE_GAME_DATA['special_teams']['Jason Myers']['fg_made']}/{LIVE_GAME_DATA['special_teams']['Jason Myers']['fg_attempts']} ({LIVE_GAME_DATA['special_teams']['Jason Myers']['fg_pct']}%)\n",
        "- Total Points Scored: {LIVE_GAME_DATA['special_teams']['Jason Myers']['points']}\n",
        "- Field Goal Distances: {', '.join(map(str, LIVE_GAME_DATA['special_teams']['Jason Myers']['kicks']))} yards\n",
        "- Perfect kicking performance\n",
        "\n",
        "KEY PLAYS & TOUCHDOWNS:\n",
        "{chr(10).join('- ' + play for play in LIVE_GAME_DATA['key_plays'])}\n",
        "\n",
        "GAME NOTES:\n",
        "- Seahawks dominated time of possession and field position\n",
        "- Patriots held scoreless until 4th quarter\n",
        "- Uchenna Nwosu's pick-six sealed the victory\n",
        "- Jason Myers scored 17 of Seahawks' 29 points\n",
        "- Drake Maye sacked 6 times, hurried throughout game\n",
        "- Seattle defense forced 3 turnovers, no turnovers on offense\n",
        "\"\"\"\n",
        "\n",
        "print(\"‚úÖ Real-time game data loaded!\")\n",
        "print(f\"üìä Final Score: SEA {LIVE_GAME_DATA['final_score']['SEA']}, NE {LIVE_GAME_DATA['final_score']['NE']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLGyXAAQTSrB",
        "outputId": "ef3803dc-d465-40df-be56-bbdd31e3ee5a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Fetching real-time Super Bowl LX data...\\n\n",
            "‚ÑπÔ∏è MVP not yet announced or not found in news\n",
            "‚úÖ Real-time game data loaded!\n",
            "üìä Final Score: SEA 29, NE 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Gradio Interface"
      ],
      "metadata": {
        "id": "section4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "APP_TITLE = \"üèà Super Bowl LX Chatbot\"\n",
        "APP_DESCRIPTION = \"\"\"**Seattle Seahawks 29, New England Patriots 13** (February 8, 2026)\n",
        "\n",
        "ü§ñ Using Llama 3.3 70B via Groq\n",
        "üìä Hybrid retrieval with official game statistics\n",
        "‚úÖ Accurate, grounded answers with proper sources\n",
        "\"\"\"\n",
        "\n",
        "def format_response(result: dict) -> str:\n",
        "    \"\"\"Format answer with sources\"\"\"\n",
        "    answer = result.get(\"answer\", \"\").strip()\n",
        "    sources = result.get(\"sources\", [])\n",
        "\n",
        "    response = f\"{answer}\"\n",
        "\n",
        "    if sources:\n",
        "        response += \"\\n\\n---\\n**üìö Sources:**\\n\"\n",
        "        for i, source in enumerate(sources, 1):\n",
        "            if source.startswith(\"http\"):\n",
        "                response += f\"{i}. [{source}]({source})\\n\"\n",
        "            else:\n",
        "                response += f\"{i}. {source}\\n\"\n",
        "\n",
        "    return response\n",
        "\n",
        "def chat_fn(message, history):\n",
        "    \"\"\"Chat function for Gradio\"\"\"\n",
        "    result = generate_answer(message, k=15)\n",
        "    return format_response(result)\n",
        "\n",
        "# Example questions\n",
        "examples = [\n",
        "    \"What was the final score?\",\n",
        "    \"Who won Super Bowl LX?\",\n",
        "    \"Who were the starting quarterbacks?\",\n",
        "    \"How did the Seahawks defense perform?\",\n",
        "    \"Tell me about Jason Myers' performance\",\n",
        "    \"How many sacks did the Seahawks get?\",\n",
        "    \"What were Drake Maye's stats?\",\n",
        "    \"Who scored the pick-six touchdown?\",\n",
        "    \"What happened in the 4th quarter?\",\n",
        "    \"What were the key turning points?\"\n",
        "]\n",
        "\n",
        "# Create interface - SIMPLIFIED VERSION\n",
        "demo = gr.ChatInterface(\n",
        "    fn=chat_fn,\n",
        "    title=APP_TITLE,\n",
        "    description=APP_DESCRIPTION,\n",
        "    examples=examples,\n",
        "    theme=gr.themes.Soft()\n",
        ")\n",
        "\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "id": "gradio",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "f2ef9b6a-fedc-4f9c-ae7b-bb32ac1aadbb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/chat_interface.py:347: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  self.chatbot = Chatbot(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://e8828b359a05593a74.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e8828b359a05593a74.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://e8828b359a05593a74.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}